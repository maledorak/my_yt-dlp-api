Alright, so there's been some hype going around with Strawberry and what looks like maybe some news with OpenAI. Now let's start with this tweet. If you've been following the news closely, Strawberry is the alleged Q-Star leak and OpenAI is implying that they're about to drop something and there's some insinuations going on. Of course, OpenAI has routinely over-promised and under-delivered this year. And if the leaks are to be believed, then the Strawberry thing is basically just a slightly better prompting strategy, like a slightly better self-prompting strategy. So let's get into it. This account, iRuleTheWorld, is the Strawberry dude. And it's pretty funny because he's like psycho-posting, what they call schizo-tweeting or schizo-posting about Strawberries. But Sam Altman replied to him. So welcome to level 2, how do you feel, or sorry, how do you feel, did I make you feel amazing, says Sam. And what they're referring to is level 2, so basically saying that OpenAI is claiming or insinuating, again, there's no benchmarks yet, there's no data, there's no disclosure. So this is all just kind of chewing through the rumor mill as fast as we can. But they're saying that they have achieved level 2 problem solving and reasoning. So great. What does that mean, and where are we at, and where are we going? Now what I want you to search and pay attention to is it looks like it's possible, this is at least what the rumors look like on Twitter, is that the model is SUS column R. If you search for that, you'll find a whole bunch of posts about this model. And so they're looking at GPT-40-2024-0806 versus SUS column R, and you see a very different behavior. And I've got the OpenAI dashboard, the platform, the AI workbench open, and I'll show you in just a second. But you see, this one gets it wrong, actually no, this one got it right. But what I'll show you in a second is that this model does not regularly get this question right. It depends on how you prompt it. Also it tends to get it right if you asked it reasoning questions before. So I'll show you that in just a second. But people are asking, you know, this model, model A, SUS column R, what model are you? And it says I'm a conversational, or based on a conversational AI by OpenAI, so on and so forth. What song is this? And it still gets a lot of stuff wrong. Let's see, what do we have here? More math. And of course, if you've been paying attention to Google, with Google's geometry and math models, it looks like math is being solved pretty quickly. Over on Reddit there's a lot of people talking about this as well. So where are we at? Where are we going? Who knows. And of course the memes and the AI-generated videos are, you know, they're something special. So far I haven't really seen anything that's super, I don't know, impressive or game-changing yet. But again, these are all leaks. This is, you know, kind of, meh. Here's another example where it gets it wrong, $9.11 billion is more than $9.9 billion. So they clearly don't have an intuitive grasp of math, but let's move on. So here is that model. So I've got it up here, and this is not the SUS column R model. This is the update. This is what everyone suspects is the model behind ChatGPT right now. So it has been updated. So I asked what's bigger, $9.11 or $9.9, and it says very confidently $9.11 is bigger than $9.9. Okay, great. So let's clear this out real quick. You see I've got the temperature set to zero. So then what I did, just to test it, I was like, how many Rs are in strawberry? Oops, sorry, that's the system message. My bad. So in this case it says it contains two Rs, but it was lowercase. Now let me show you, let me see if this works, because I did this literally just a couple seconds ago. Oh, nope, it got it wrong again. So it's interesting how inconsistent it is, because I asked it and it got it right. Okay, so I added a question mark, and it got three Rs. So look at that. You'd think that if the model was human level reasoning, it could handle whether or not there was a question mark. And this is nothing new, like having been in prompt engineering since GPT-2, these models are incredibly sensitive to how you word things, to the order that you say things. But now that it got that right, let me show you what happens. Let's see, which is bigger, $9.11 or $9.9, it'll probably get it right. $9.9 is bigger than $9.11. So, you know, what's going on here? It remains to be seen, but people are still finding ways that this SUS column R chatbot is broken. So I'm not really anticipating a whole lot, like I think it's just hype. I don't know if it's actually Q-star, I don't know if it's actually strawberry, who knows. Maybe there's something that the model is doing better. And again, we don't have the data yet. There's plenty of criticism to go around on the quality of benchmarks, whether or not benchmarks are even useful, so on and so forth. So I tried the same thing over here on Google, and Gemini 1.5 Pro, this isn't even ultra, this is just Gemini Pro, gets it correct right off the bat. So let's see, zoom in just a little bit. Can I collapse this? I don't think so. Anyways, so $9.9, and it gives a little bit of reasoning, but what's interesting is it gives you the answer immediately and then explains it, which is nice. So then, let's clear that, delete, delete, how many Rs in strawberry, because you'd think that if a model has human-level reasoning, well that's not right. Let's try it again, how many Rs are in strawberry, because again, if these things had human-level reasoning, there are two Rs in the word strawberry. I swear it got it right when I asked it a little while ago. Let's see if we can do, how many Rs are in strawberry, okay. But I think the point stands is these very simple tests, if they were at human-level reasoning, if they weren't just processing in a certain way, then they'd be doing a little bit better. And of course, I'm also the same guy that has been saying like, oh these things, there's something else going on, there's something special here, and I do believe that. Here's Claude, it gets it right immediately, 9.9 is bigger than 9.1, how many Rs are in the word strawberry, let's see what it says, there are two Rs in the word, so they all get that wrong. I think that a lot of what's going on is the difference in perception. Now again, depending on what you're working on, because if you talk philosophy, if you talk verbal reasoning, these things are really good, but at the same time, I think that there's just too much hype. So, I don't know, let me know what you think in the comments, we'll see if it all pans out, we'll see what comes of it. But yeah, so far I'm pretty nonplussed by the whole thing, you know, I'm a little bit tired of the hype and the over-promising and under-delivering, and I know some people are excited by the hype, hype feels good, but at the same time, I really just want to see some real progress. So, cheers.
